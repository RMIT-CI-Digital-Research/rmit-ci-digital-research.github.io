{"News/Event/Event_1":{"title":"Conference","links":[],"tags":[],"content":"Test"},"News/NCP/Visa":{"title":"NCP 2024","links":[],"tags":[],"content":"Website:\nbio.visaforchina.cn/MEL3_EN/\nVisa Category\n(F)Exchange, visits, study tours or other relevant activities\nFee\nbio.visaforchina.cn/MEL3_EN/upload/20240229/ddaf471401ac47b688116bc64619eb12.pdf"},"News/News":{"title":"News","links":["News/NCP/Visa"],"tags":[],"content":"For NCP 2024\nNCP 2024 Visa Application"},"News/OENG1191/Classtypes":{"title":"Class types","links":[],"tags":[],"content":"public class test : MonoBehaviour\n\nThe class is accessible from any other class or assembly.\n\nprivate class test : MonoBehaviour​\n\nThe class is accessible only within its containing class. It’s the most restrictive access level​\n\nprotected class test : MonoBehaviour​\n\nThe class is accessible only within its containing class and derived classes.​\n\ninternal class test : MonoBehaviour\n\nThe class is accessible only within the same assembly\n"},"News/OENG1191/Installation":{"title":"Week 11 Unity Installation","links":[],"tags":[],"content":"Step 1: Install Unity Hub\nGo to unity.com/download, find Download for Windows\n\nThis will initial downloading of Unity Hub.\nStep 2: Install Unity Editor\nInside Unity Hub, go to installs\n\nfind and download the latest Long Term Support (LTS) version: LTS Release2022.3.29f1\n\n\n\n                  \n                  Warning\n                  \n                \nMicrosoft Visual Studio as a component is required for this session.\n\n\nStep 3: Check installation\nYou should find you Unity installation as below:\n"},"News/OENG1191/Week-11-Unity":{"title":"Week 11 Unity","links":["News/OENG1191/namespaces","News/OENG1191/inheritance","News/OENG1191/Classtypes","News/OENG1191/functions","News/OENG1191/if"],"tags":[],"content":"Code section explained:\n\n\n                  \n                  Namespace Declarations \n                  \n                \nNo not change this part\nThis part is to include functions from other libraries.\nWhat is Namespaces?\n\nusing System.Collections;\nusing System.Collections.Generic;\nusing UnityEngine;\n\n\n                  \n                  Main script \n                  \n                \nStart with defining variables.\nWhat is inheritance?\nWhat are the class types?\n\npublic class DoorScript : MonoBehaviour\n{\n    public GameObject Text;\n    public bool reverse;\n    private bool inTheArea;\n    private bool doorOpened;\n\n\n                  \n                  Start function \n                  \n                \nWhat are functions?\nStart function is called only once before the first frame update. In this script, it initiated the value of the 2 bool variable.\n\n    void Start()\n    {\n        inTheArea = false;\n        doorOpened = false;\n    }\n\n\n                  \n                  Update function \n                  \n                \nUpdate is called once per frame.\nWhat is the if structure?\nif (Input.GetKeyDown(KeyCode.E) &amp;&amp; inTheArea) is a logical expression which means if ‘E’ is keyed and bool variable inTheArea is Ture, then execute the code in the following ’{}‘.\n\n    // Update is called once per frame\n    void Update()\n    {\n        if (Input.GetKeyDown(KeyCode.E) &amp;&amp; inTheArea)\n        {\n            Debug.Log(&quot;E down!&quot;);\n            if (doorOpened)\n            {\n                transform.localEulerAngles = new Vector3(0, 0, 0);\n                doorOpened = false;\n                Debug.Log(&quot;closed!&quot;);\n            }\n            else\n            {\n                if (reverse)\n                {\n                    transform.localEulerAngles = new Vector3(0, 0, 130);\n                }\n                else\n                {\n                    transform.localEulerAngles = new Vector3(0, 0, -130);\n                }\n                doorOpened = true;\n                Debug.Log(&quot;opened!&quot;);\n            }\n        }\n    }\n\n\n\n                  \n                  Trigger function for entry \n                  \n                \nThe method OnTriggerEnter is a special Unity method that gets called automatically when another object enters a trigger collider attached to the object this script is attached to.\nIn this case, the function will be called when the avatar is near the door.\n\n    private void OnTriggerEnter(Collider other)\n    {\n        inTheArea = true;\n        Text.SetActive(true);\n        Debug.Log(&quot;Entered! &quot; + inTheArea);\n    }\n\n\n                  \n                  Trigger function for entry \n                  \n                \nThe method OnTriggerEnter is a special Unity method that gets called automatically when another object enters a trigger collider attached to the object this script is attached to.\nIn this case, the function will be called when the avatar is near the door.\n\n  private void OnTriggerExit(Collider other)\n    {\n        inTheArea = false;\n        Text.SetActive(false);\n        Debug.Log(&quot;Exited! &quot; + inTheArea);\n    }\n}"},"News/OENG1191/functions":{"title":"Different functions in MonoBehaviour​","links":[],"tags":[],"content":"\nAll the available functions:\nStart()\nUpdate()\nFixedUpdate()\nLateUpdate()\nOnGUI()\nOnDisable()\nOnEnable()\nRefer: docs.unity3d.com/ScriptReference/MonoBehaviour.html\n"},"News/OENG1191/if":{"title":"If - else structure","links":[],"tags":[],"content":""},"News/OENG1191/inheritance":{"title":"Inheritance","links":[],"tags":[],"content":"\n\ngraph TD\nMonoBehaviour --&gt; test\n"},"News/OENG1191/logical":{"title":"Logical expressions","links":[],"tags":[],"content":""},"News/OENG1191/namespaces":{"title":"Namespaces","links":[],"tags":[],"content":"\n"},"News/Recruitment/PhD-Application-instruction":{"title":"PhD Application instruction","links":[],"tags":[],"content":"Pass"},"News/Recruitment/Test-PhD-hire":{"title":"PhD opportunity","links":["News/Recruitment/PhD-Application-instruction"],"tags":[],"content":"We invite aspiring scholars to join our esteemed PhD program, designed for individuals with a passion for discovery and a commitment to advancing knowledge. Our program fosters a vibrant academic community where students can engage in groundbreaking research alongside distinguished faculty members. We offer a comprehensive curriculum, state-of-the-art resources, and a supportive environment to help you achieve your academic and professional goals. By joining our PhD program, you’ll have the chance to develop expertise in your chosen field, collaborate on innovative projects, and prepare for impactful careers in academia, industry, or public service.\nIf you are interested, please refer this Instruction."},"Research/Demonstration/VR-experiment":{"title":"Virtual Reality Experiment","links":[],"tags":[],"content":""},"Research/Latest-Publications":{"title":"Latest Publications","links":["Research/Publication/wuRealtimeMixedRealitybased2022","Research/Publication/"],"tags":[],"content":"\n\n                  \n                   Real-time mixed reality-based visual warning for construction workforce safety\n                  \n                \n\nCheck all publications Here"},"Research/Publication/chenUsingContextGuidedData2023":{"title":"Using Context-Guided data Augmentation, lightweight CNN, and proximity detection techniques to improve site safety monitoring under occlusion conditions","links":[],"tags":[],"content":"Chen, H, Hou, L, Zhang, G (Kevin) &amp; Wu, S 2023, ‘Using Context-Guided data Augmentation, lightweight CNN, and proximity detection techniques to improve site safety monitoring under occlusion conditions’, Safety Science, vol. 158, p. 105958.\nonline local pdf\nAbstract\nAutomated recognition of image patterns in surveillance cameras is beneficial for safety monitoring. A repre­ sentative application is visual proximity detection for accident prevention. However, existing deep learning (DL)based proximity detection methods are likely to be inaccurate due to congestion, background clutter, and oc­ clusion in construction sites. Another problem is that most of these methods cannot suffice computing capability, network training efficiency, and performance accuracy at the same time. This study first presents a novel contextguided data augmentation method that addresses the performance loss issue due to object occlusion. This method places new instances on images based on contextual image information rather than randomly erasing images to simulate occlusion circumstances. Next, a light-weight and less-costly DL model named YOLOv4-EFNB0 is formulated for multi-class construction resource detection in real-time. Moreover, this study presents a proactive proximity detection application by integrating YOLOv4-EFNB0 with homography transformation. Based on the experiment, YOLOv4-EFNB0 demonstrates a better object detection outcome when trained on the augmented dataset over the Moving Objects in Construction Sites (MOCS) baseline dataset. This study also conducts a feasibility test for the visual proximity detection application. The results indicate the application has a high accuracy rate and a fast speed, namely, 96.76% in 25 Frames Per Second (FPS), which can facilitate the auto­ mation of safety monitoring and inspection."},"Research/Publication/index":{"title":"Publications","links":[],"tags":[],"content":"Check out our publications !"},"Research/Publication/wuCognitiveErgonomicsbasedAugmented2023":{"title":"Cognitive ergonomics-based Augmented Reality application for construction performance","links":[],"tags":[],"content":"Wu, S, Hou, L, Chen, H, Zhang, G (Kevin), Zou, Y &amp; Tushar, Q 2023, ‘Cognitive ergonomics-based Augmented Reality application for construction performance’, Automation in Construction, vol. 149, p. 104802.\nonline local pdf\nAbstract\nThere is a growing interest in exploring the use of wearable Augmented Reality (AR) devices to improve the task performance of construction workers. However, user interaction with AR has not been well understood in the current literature, which may result in poor usability, occupational hazards, and low acceptance. To bridge this gap, this study introduced cognitive ergonomics theory to design and develop an AR application for improving the kinaesthetic performance of construction workers conducting onsite assembly tasks. The methodology of this study is three-fold. First, articles in relation to cognitive ergonomics were reviewed to propose a unique cognitive model that reveals the cognitive mechanisms of construction workers, including human information processing, selective attention, and attention resources. Second, the characteristics of existing AR application functions were synthesised to develop a customised and user-friendly wearable AR application that aligns with the identified cognitive mechanisms. Third, a rebar-tying experiment was conducted to validate the developed AR application. The results indicate that the experimenters instructed by the application can complete the task independently without the need to seek after expert assistance; the application has a potential to foster the skill development of construction workers and enhance their kinaesthetic performance; and the proposed cognitive model and the AR development principles are well aligned from the perspective of cognitive ergonomics, which could promote the uptake of wearable AR in the construction industry."},"Research/Publication/wuRealtimeMixedRealitybased2022":{"title":"Real-time mixed reality-based visual warning for construction workforce safety","links":["Team/PhD/Shaoze","Team/PhD/Haosen"],"tags":["VR","AR","BIM"],"content":"Wu, S, Hou, L, Zhang, G (Kevin) &amp; Chen, H 2022, ‘Real-time mixed reality-based visual warning for construction workforce safety’, Automation in Construction, vol. 139, p. 104252.\nAbstract\nSpatial locations of personnel, equipment, and materials are constantly changing as construction projects progress. The dynamic nature of the construction industry affects workers’ performance of identifying hazards. Even though a great deal of effort has been made to improve construction safety, the construction industry still witnesses a high accident rate. In order to complement the existing body of knowledge relating to construction safety, this paper integrates Digital Twin (DT), Deep Learning (DL), and Mixed Reality (MR) technologies into a newly developed real-time visual warning system, which enables construction workers to proactively determine their safety status and avoid accidents. Next, system tests were conducted under three quasi-on-site scenarios, and the feasibility was proven in terms of synchronising construction activities over a large area and visually representing hazard information to its users. These evidenced merits of the development testing scenarios can improve workers’ risk assessment accuracy, reinforce workers’ safety behaviour, and provide a new perspective for construction safety managers to analyse construction safety status."},"Research/Topics/AI":{"title":"Artificial Intelligence","links":[],"tags":["AI"],"content":"Artificial Intelligence (AI) refers to the field of computer science dedicated to developing systems or machines that can perform tasks that typically require human intelligence. These tasks include learning, reasoning, problem-solving, perception, and natural language understanding. AI systems can be broadly categorised into:\n\n\nNarrow AI (Weak AI): This type of AI is designed to perform a specific task or a narrow range of tasks. Examples include voice assistants like Siri and Alexa, recommendation systems, and image recognition software.\n\n\nGeneral AI (Strong AI): A more advanced form of AI that has not yet been realised. General AI would have the ability to understand, learn, and apply knowledge across a wide range of tasks, similar to human intelligence.\n\n\nMachine Learning (ML): A subset of AI that involves the use of algorithms and statistical models to enable computers to learn from and make decisions based on data.\n\n\nDeep Learning: A subset of machine learning that utilises neural networks with many layers (deep neural networks) to analyse various forms of data. Deep learning is used in areas such as image and speech recognition.\n\n\nAI is increasingly integrated into various industries, including healthcare, finance, transportation, and entertainment, offering innovative solutions that enhance efficiency and decision-making."},"Research/Topics/AR":{"title":"Augmented Reality","links":["tags/AR","Team/PhD/Shaoze"],"tags":["AR"],"content":"AR\nRelated Researcher: Shaoze\nAugmented reality (AR) is a technology that overlays digital information, such as images, videos, or data, onto the real world. Unlike virtual reality, which creates a fully immersive digital environment, AR enhances the real-world environment by adding digital elements to it. These digital elements can be seen through devices such as smartphones, tablets, smart glasses, or AR headsets.\nExamples of augmented reality include:\n\nAR Games: Games like Pokémon GO superimpose virtual characters and objects onto the real-world environment seen through a mobile device.\nNavigation: Some AR apps can display navigation information, such as arrows or directions, overlaid on the real world to guide users.\nMaintenance and Repair: AR can provide technicians with detailed instructions superimposed directly onto the equipment they are working on.\nRetail: Virtual fitting rooms allow customers to see how clothes or accessories would look on them without physically trying them on.\n\nOverall, AR enhances the user’s perception of reality by blending digital content seamlessly with the real world."},"Research/Topics/BIM":{"title":"Building Information Modelling","links":[],"tags":[],"content":"Building Information Modelling (BIM) is a digital representation of the physical and functional characteristics of a facility. It is a collaborative process that allows architects, engineers, and construction professionals to design, construct, and manage buildings and infrastructure projects more efficiently. BIM involves the generation and management of digital models that encapsulate geometry, spatial relationships, geographic information, and quantities and properties of building components.\nKey features of BIM include:\n\n3D Visualisation: It allows for three-dimensional visualization of the building, enabling better planning and design.\nCollaboration: Multiple stakeholders can access the same model, facilitating collaboration and reducing errors and rework.\nData Management: BIM allows for storing comprehensive information about building components, helping with construction planning and asset management.\nLifecycle Management: From conceptual design through construction, operation, and demolition, BIM is used throughout the entire lifecycle of the building.\n\nBIM is increasingly being used in the architecture, engineering, and construction (AEC) industry to improve project outcomes and reduce costs."},"Research/Topics/LCA":{"title":"Life Cycle Assessment","links":[],"tags":["LCA"],"content":"Life Cycle Assessment (LCA) is a systematic method used to evaluate the environmental impacts associated with all stages of a product’s life cycle, from raw material extraction through materials processing, manufacture, distribution, use, and disposal or recycling. The main goal of LCA is to provide a comprehensive assessment that helps to understand and minimise the overall environmental footprint of a product or service.\nKey steps in an LCA include:\n\n\nGoal and Scope Definition: Clearly defining the purpose, system boundaries, and scope of the LCA, including the functional unit that will be assessed.\n\n\nLife Cycle Inventory (LCI): Collecting and quantifying data on energy, water, and material inputs and environmental releases (emissions to air, water, and soil) across the entire life cycle of the product or service.\n\n\nLife Cycle Impact Assessment (LCIA): Evaluating the potential environmental impacts based on the inventory data collected. This may include impacts such as global warming potential, acidification, eutrophication, resource depletion, and human toxicity.\n\n\nInterpretation: Analysing the results, drawing conclusions, and providing recommendations to improve the product’s environmental performance. This step may include identifying significant issues, evaluating the reliability of the results, and considering improvement opportunities.\n\n\nLCA helps organisations and policymakers understand the full environmental impact of products or services and make informed decisions to improve sustainability."},"Research/Topics/VR":{"title":"Virtual Reality","links":["Team/PhD/Shaoze"],"tags":[],"content":"Related Researcher: Shaoze\nVirtual reality (VR) is a technology that creates an immersive, computer-generated environment that can simulate physical presence in real or imagined worlds. It often involves using a headset or specialized display that covers the eyes and provides a stereoscopic view of the virtual environment. Additionally, VR may include haptic feedback, sound, and motion tracking to enhance the immersion, allowing users to interact with the virtual environment more naturally.\nVR is used in various fields, including gaming, training, education, and therapy, by providing experiences that range from fully immersive games to virtual classrooms and therapy sessions."},"Team/PhD/Hana":{"title":"Hana Sun","links":[],"tags":["LCA"],"content":"🦘"},"Team/PhD/Haosen":{"title":"Haosen Chen","links":[],"tags":["BIM","AI","AR","VR"],"content":"🦘"},"Team/PhD/Ping":{"title":"Ping Chai","links":[],"tags":[],"content":"Who loves keyboard"},"Team/PhD/Sajith":{"title":"Sajith Wettewa","links":[],"tags":[],"content":""},"Team/PhD/Sang":{"title":"Sang Du","links":[],"tags":["BIM","GNN","AI","IFC"],"content":"🦘"},"Team/PhD/Shanuka":{"title":"Shanuka Dodampegama","links":[],"tags":[],"content":""},"Team/PhD/Shaoze":{"title":"Shaoze Wu","links":["Research/Publication/wuRealtimeMixedRealitybased2022"],"tags":["VR","AR","BIM"],"content":"His works:\n\nwuRealtimeMixedRealitybased2022\n"},"Team/PhD/Zoe":{"title":"Zoe Zou","links":[],"tags":[],"content":""},"Team/index":{"title":"Team","links":[],"tags":[],"content":"Our Research Team"},"index":{"title":"Innovate, Integrate, Inspire","links":["News/News","Research/Topics/BIM","Research/Topics/AI","Research/Topics/VR","Research/Topics/AR","Research/Topics/LCA","Research/Demonstration/VR-experiment","Research/Latest-Publications","Team/PhD/Shaoze","Team/PhD/Haosen","Team/PhD/Sang","Team/PhD/Ping","Team/PhD/Sajith","Team/PhD/Hana","Team/PhD/Shanuka","Team/PhD/Zoe"],"tags":[],"content":"Transclude of News\nThe Civil Infrastructure Digital Research Team is dedicated to pioneering advancements in the construction and maintenance of essential public works through cutting-edge digital technology. Our team of experts focuses on harnessing the power of data analytics, artificial intelligence, and innovative modelling techniques to improve the resilience, efficiency, and sustainability of infrastructure systems worldwide.\nWe also running the OENG1191 Building Information Modelling course of RMIT’s Bachelor of Engineering (Civil and Infrastructure).\nResearch\n\n\n                  \n                  Our Research Topics \n                  \n                \n\n\n                  \n                   Building Information Modelling\n                  \n                \n\n\n\n                  \n                   Artificial Intelligence\n                  \n                \n\n\n\n                  \n                   Virtual Reality\n                  \n                \n\n\n\n                  \n                   Argumented Reality\n                  \n                \n\n\n\n                  \n                   Life Cycle Assessment\n                  \n                \n\n\n\n\n                  \n                  Our Research Demonstrations \n                  \n                \n\n\n                  \n                   VR experiment\n                  \n                \n\n\n\n                  \n                   VR experiment\n                  \n                \n\n\n\n                  \n                   VR experiment\n                  \n                \n\n\nTransclude of Latest-Publications\nOur Team\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}}